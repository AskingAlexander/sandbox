{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import keras\n",
    "import pandas as pd\n",
    "import math\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fuel.datasets.hdf5 import H5PYDataset\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from IPython.display import display\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, Activation, Dropout, Conv2D, Conv2DTranspose\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Autoencoder Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_chns = 28, 28, 1\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    original_img_size = (img_chns, img_rows, img_cols)\n",
    "else:\n",
    "    original_img_size = (img_rows, img_cols, img_chns)\n",
    "\n",
    "batch_size = 100\n",
    "latent_dim = 128\n",
    "intermediate_dim = 512\n",
    "epsilon_std = 1.0\n",
    "epochs = 10\n",
    "activation = 'relu'\n",
    "dropout = 0.5\n",
    "learning_rate = 0.001\n",
    "decay = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1) / 255.\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_enc_conv_layers(stage, **kwargs):\n",
    "    conv_name = '_'.join(['enc_conv', str(stage)])\n",
    "    bn_name = '_'.join(['enc_bn', str(stage)])\n",
    "    layers = [\n",
    "        Conv2D(name=conv_name, **kwargs),\n",
    "        BatchNormalization(name=bn_name),\n",
    "        Activation(activation),\n",
    "    ]\n",
    "    return layers\n",
    "\n",
    "def create_dense_layers(stage, width):\n",
    "    dense_name = '_'.join(['enc_conv', str(stage)])\n",
    "    bn_name = '_'.join(['enc_bn', str(stage)])\n",
    "    layers = [\n",
    "        Dense(width, name=dense_name),\n",
    "        BatchNormalization(name=bn_name),\n",
    "        Activation(activation),\n",
    "        Dropout(dropout),\n",
    "    ]\n",
    "    return layers\n",
    "\n",
    "def inst_layers(layers, in_layer):\n",
    "    x = in_layer\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, list):\n",
    "            x = inst_layers(layer, x)\n",
    "        else:\n",
    "            x = layer(x)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_filters=64\n",
    "enc_layers = [\n",
    "    create_enc_conv_layers(stage=1, filters=enc_filters, kernel_size=3, strides=1, padding='same'),\n",
    "    create_enc_conv_layers(stage=2, filters=enc_filters, kernel_size=3, strides=1, padding='same'),\n",
    "    create_enc_conv_layers(stage=3, filters=enc_filters, kernel_size=3, strides=2, padding='same'),\n",
    "    Flatten(),\n",
    "    create_dense_layers(stage=4, width=intermediate_dim),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Input(batch_shape=(batch_size,) + original_img_size)\n",
    "_enc_dense = inst_layers(enc_layers, x)\n",
    "\n",
    "_z_mean_1 = Dense(latent_dim)(_enc_dense)\n",
    "_z_log_var_1 = Dense(latent_dim)(_enc_dense)\n",
    "\n",
    "z_mean = _z_mean_1\n",
    "z_log_var = _z_log_var_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reparameterization Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sampling(args, batch_size=batch_size, latent_dim=latent_dim, epsilon_std=epsilon_std):\n",
    "    z_mean, z_log_var = args\n",
    "    \n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    \n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dec_trans_conv_layers(stage, **kwargs):\n",
    "    conv_name = '_'.join(['dec_trans_conv', str(stage)])\n",
    "    bn_name = '_'.join(['dec_bn', str(stage)])\n",
    "    layers = [\n",
    "        Conv2DTranspose(name=conv_name, **kwargs),\n",
    "        BatchNormalization(name=bn_name),\n",
    "        Activation(activation),\n",
    "    ]\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dec_filters = 64\n",
    "decoder_layers = [\n",
    "    create_dense_layers(stage=10, width=14 * 14 * 64),\n",
    "    Reshape((14, 14, 64)),\n",
    "    create_dec_trans_conv_layers(11, filters=dec_filters, kernel_size=3, strides=1, padding='same'),\n",
    "    create_dec_trans_conv_layers(12, filters=dec_filters, kernel_size=3, strides=1, padding='same'),\n",
    "    create_dec_trans_conv_layers(13, filters=dec_filters, kernel_size=3, strides=2, padding='same'),\n",
    "    Conv2DTranspose(name='x_decoded', filters=1, kernel_size=1, strides=1, activation='sigmoid'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_dec_out = inst_layers(decoder_layers, z)\n",
    "_output = _dec_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def kl_loss(x, x_decoded_mean):\n",
    "    kl_loss = - 0.5 * K.sum(1. + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "   \n",
    "    return K.mean(kl_loss)\n",
    "\n",
    "def logx_loss(x, x_decoded_mean):\n",
    "    x = K.flatten(x)\n",
    "    x_decoded_mean = K.flatten(x_decoded_mean)\n",
    "    xent_loss = img_rows * img_cols * img_chns * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "    return xent_loss\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    return logx_loss(x, x_decoded_mean) + kl_loss(x, x_decoded_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vae = Model(inputs=x, outputs=_output)\n",
    "optimizer = Adam(lr=learning_rate, decay=decay)\n",
    "vae.compile(optimizer=optimizer, loss=vae_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "history = vae.fit(\n",
    "    X_train, X_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[TQDMNotebookCallback()],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "done = time.time()\n",
    "elapsed = done - start\n",
    "print(\"Elapsed: \", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "display(df.describe(percentiles=[0.25 * i for i in range(4)] + [0.95, 0.99]))\n",
    "df.plot(figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(x, z_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_z = Input(shape=(latent_dim,))\n",
    "g_output = inst_layers(decoder_layers, g_z)\n",
    "generator = Model(g_z, g_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "for j in range(n):\n",
    "    for i in range(n):\n",
    "        z_sample = np.random.normal(size=latent_dim).reshape(1, latent_dim)\n",
    "        x_decoded = generator.predict(z_sample, batch_size=1)\n",
    "        digit = x_decoded.reshape(digit_size, digit_size, img_chns)\n",
    "        \n",
    "        d_x = i * digit_size\n",
    "        d_y = j * digit_size\n",
    "        figure[d_x:d_x + digit_size, d_y:d_y + digit_size] = digit[:, :, 0]\n",
    "        \n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_path = \"saved_models/vae-m1-mnist-encoder.hdf5\"\n",
    "encoder.save(encoder_path)\n",
    "\n",
    "generator_path = \"saved_models/vae-m1-mnist-generator.hdf5\"\n",
    "generator.save(generator_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_encoder = keras.models.load_model(encoder_path)\n",
    "test_generator = keras.models.load_model(generator_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "3f93cef34a914b66be9af95fafe00ed5": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
