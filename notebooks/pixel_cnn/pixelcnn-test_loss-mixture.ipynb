{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:52:12.024794Z",
     "start_time": "2019-05-13T12:52:10.263788Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import keras\n",
    "import pandas as pd\n",
    "import math\n",
    "import joblib\n",
    "import json\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import logistic\n",
    "from scipy.special import softmax\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from keras.layers import (Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, \n",
    "                          Activation, Dropout, Conv2D, Conv2DTranspose, LocallyConnected2D,\n",
    "                          Concatenate, Add, Multiply)\n",
    "from keras.engine import InputSpec\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.optimizers import RMSprop, Adam, SGD\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from pixelcnn_helpers import pixelcnn_loss, sigmoid, compute_pvals, compute_mixture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:52:12.037603Z",
     "start_time": "2019-05-13T12:52:12.026336Z"
    }
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_chns = 2, 2, 3\n",
    "original_img_size = (img_rows, img_cols, img_chns)\n",
    "num_samples = 1000\n",
    "\n",
    "batch_size = int(os.environ.get('BATCH_SIZE', 1))\n",
    "epochs = int(os.environ.get('EPOCHS', 1000))\n",
    "activation = os.environ.get('ACTIVATION', 'relu')\n",
    "learning_rate = float(os.environ.get('LEARNING_RATE', 0.001))\n",
    "resnet_depth = int(os.environ.get('RESNET_DEPTH', 1))\n",
    "n_components = int(os.environ.get('MIXTURE_COMPONENTS', 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a dataset based on mixtures of logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling and shifting a logistic: http://www.math.wm.edu/~leemis/chart/UDR/PDFs/LogisticS.pdf\n",
    "\n",
    "\n",
    "X ~ Logistic(m, s)\n",
    "\n",
    "Y = cX\n",
    "\n",
    "then:\n",
    "\n",
    "Y ~ Logistic(m, s*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:52:12.374878Z",
     "start_time": "2019-05-13T12:52:12.039418Z"
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic m:\n",
      "[[[[-0.92156863  0.96078431]\n",
      "   [-0.92156863  0.96078431]\n",
      "   [-0.92156863  0.96078431]]\n",
      "\n",
      "  [[-0.92156863  0.96078431]\n",
      "   [-0.92156863 -0.92156863]\n",
      "   [-0.92156863 -0.92156863]]]\n",
      "\n",
      "\n",
      " [[[-0.92156863 -0.21568627]\n",
      "   [-0.92156863  0.96078431]\n",
      "   [-0.92156863 -0.92156863]]\n",
      "\n",
      "  [[-0.92156863 -0.92156863]\n",
      "   [-0.92156863 -0.92156863]\n",
      "   [-0.92156863  0.96078431]]]]\n",
      "Logistic s\n",
      "[[[[3.14095501 3.14095501]\n",
      "   [3.14095501 3.14095501]\n",
      "   [3.14095501 3.14095501]]\n",
      "\n",
      "  [[3.14095501 3.14095501]\n",
      "   [3.14095501 3.14095501]\n",
      "   [3.14095501 3.14095501]]]\n",
      "\n",
      "\n",
      " [[[3.14095501 3.14095501]\n",
      "   [3.14095501 3.14095501]\n",
      "   [3.14095501 3.14095501]]\n",
      "\n",
      "  [[3.14095501 3.14095501]\n",
      "   [3.14095501 3.14095501]\n",
      "   [3.14095501 3.14095501]]]]\n",
      "Mixture w\n",
      "[[[[0.5 0.5]\n",
      "   [0.5 0.5]\n",
      "   [0.5 0.5]]\n",
      "\n",
      "  [[0.5 0.5]\n",
      "   [0.5 0.5]\n",
      "   [0.5 0.5]]]\n",
      "\n",
      "\n",
      " [[[0.5 0.5]\n",
      "   [0.5 0.5]\n",
      "   [0.5 0.5]]\n",
      "\n",
      "  [[0.5 0.5]\n",
      "   [0.5 0.5]\n",
      "   [0.5 0.5]]]]\n",
      "(1000, 2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(127)\n",
    "\n",
    "# logistic std deviation of 1 pixel level\n",
    "unit_s = 1 / math.pi * math.sqrt(3)\n",
    "\n",
    "def train_data_simple(num_samples):\n",
    "    # Generate pixels using exactly 2 mixture components\n",
    "    n_comp = 2\n",
    "    \n",
    "    # Each pixel is a independent single logstic\n",
    "    X_train = np.zeros((num_samples, img_rows, img_cols, img_chns))\n",
    "    \n",
    "    # Set the distribution values to fixed values so we can tell the difference\n",
    "    m = np.array([\n",
    "        [\n",
    "            [[10.,  250.],  [10, 250.],  [10, 250.]],\n",
    "            [[10.,  250.],  [10., 10. ], [10., 10.]]\n",
    "        ], \n",
    "        [\n",
    "            [[10.,  100.],  [10., 250. ], [10., 10.]], \n",
    "            [[10.,  10.],  [10., 10. ], [10., 250.]]\n",
    "        ], \n",
    "    ])\n",
    "    s = 10 * unit_s * np.ones((img_rows, img_cols, img_chns, n_comp))\n",
    "    w = np.ones((img_rows, img_cols, img_chns, n_comp))\n",
    "    w = w / w.sum(axis=3)[:, :, :, np.newaxis]\n",
    "    \n",
    "    #m = np.random.normal(127.5, 40, (img_rows, img_cols, img_chns, n_comp))\n",
    "    #s = np.random.uniform(1 * unit_s, 40 * unit_s, (img_rows, img_cols, img_chns, n_comp))\n",
    "    #\n",
    "    ## Each row has same mxiture weight\n",
    "    #w = np.random.randint(1, 10, (img_rows, img_cols, img_chns, n_comp))\n",
    "    #w = w / w.sum(axis=3)[:, :, :, np.newaxis]\n",
    "    \n",
    "    for n in range(num_samples):\n",
    "        for i in range(img_rows):\n",
    "            for j in range(img_cols):\n",
    "                for k in range(img_chns):\n",
    "                    pixels = []\n",
    "                    for c in range(n_comp):\n",
    "                        pixels.append(np.random.logistic(m[i, j, k, c], s[i, j, k, c], 1))\n",
    "                    index = np.argmax(np.random.multinomial(1, w[i, j, k])) \n",
    "                    X_train[n, i, j, k] = max(min(int(pixels[index]), 255), 0)\n",
    "                \n",
    "    print('Logistic m:')\n",
    "    print((m - 127.5) / 127.5)\n",
    "    print('Logistic s')\n",
    "    print(np.log(127.5 / s))\n",
    "    print('Mixture w')\n",
    "    print(w)\n",
    "    return X_train, (m, s, w)\n",
    "\n",
    "X_train, params = train_data_simple(num_samples)\n",
    "X_train = (X_train - 127.5) / 127.5\n",
    "print(X_train.shape)\n",
    "#print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:52:12.537794Z",
     "start_time": "2019-05-13T12:52:12.376308Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = min(num_samples, 5)\n",
    "figure = np.zeros((img_rows * n, img_cols * 2, img_chns)).astype(int)\n",
    "for i in range(n):\n",
    "    orig_img = (X_train[i] * 127.5 + 127.5).astype(int)\n",
    "    dy = img_rows * i\n",
    "    figure[dy:dy + img_rows, :img_cols] = orig_img\n",
    "    \n",
    "    # Digitize\n",
    "    #img = orig_img #.astype(float) / 255\n",
    "    #figure[dy:dy + img_rows, img_cols:2 * img_cols] = img\n",
    "\n",
    "plt.figure(figsize=(n * 4, 5))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:52:12.555373Z",
     "start_time": "2019-05-13T12:52:12.543584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.        , -0.8745098 ,  0.94509804],\n",
       "        [ 1.        , -0.85098039, -0.95294118]],\n",
       "\n",
       "       [[-0.9372549 ,  0.99215686, -0.94509804],\n",
       "        [-0.96078431, -0.96078431,  0.85882353]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[15,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pixel CNN Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:52:12.730006Z",
     "start_time": "2019-05-13T12:52:12.557696Z"
    }
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_last':\n",
    "    bn_axis = 3\n",
    "else:\n",
    "    bn_axis = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:52:13.270631Z",
     "start_time": "2019-05-13T12:52:12.731470Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Work around Keras/tensorboard bug: https://github.com/keras-team/keras/issues/10074\n",
    "K.clear_session()\n",
    "\n",
    "main_input = Input(shape=original_img_size, name='main_input')\n",
    "\n",
    "ms = []\n",
    "invss = []\n",
    "weights = []\n",
    "for channel in range(img_chns):\n",
    "    x = Lambda(lambda x: x * 0.)(main_input)\n",
    "    x = Flatten()(x)\n",
    "    decoder_out_m_ = Dense(img_rows * img_cols * n_components, name='x_m' + str(channel),\n",
    "                           bias_initializer='glorot_uniform')(x)\n",
    "    decoder_out_m_ = Lambda(lambda x: x)(decoder_out_m_)\n",
    "    decoder_out_m = Reshape((img_rows, img_cols, n_components))(decoder_out_m_)\n",
    "    ms.append(decoder_out_m)\n",
    "    \n",
    "    decoder_out_invs_ = Dense(img_rows * img_cols * n_components, name='x_s' + str(channel),\n",
    "                              activation='sigmoid', bias_initializer='glorot_uniform')(x)\n",
    "    decoder_out_invs = Lambda(lambda x: 5. * x + 2)(decoder_out_invs_)\n",
    "    decoder_out_invs = Reshape((img_rows, img_cols, n_components))(decoder_out_invs)\n",
    "    \n",
    "    invss.append(decoder_out_invs)\n",
    "   \n",
    "    x_reshape = Reshape((img_rows, img_cols, img_chns))(x)\n",
    "    mixture_weights = LocallyConnected2D(name='weights' + str(channel),\n",
    "                                         filters=n_components, kernel_size=1, strides=1,\n",
    "                                         bias_initializer='ones')(x_reshape)\n",
    "    weights.append(mixture_weights)\n",
    "\n",
    "out_m = Concatenate()(ms)\n",
    "out_invs = Concatenate()(invss)\n",
    "out_weights = Concatenate()(weights)\n",
    "main_output = Concatenate()([out_m, out_invs, out_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:52:13.394310Z",
     "start_time": "2019-05-13T12:52:13.274034Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 2, 2, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2, 2, 3)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 2, 2, 3)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 2, 2, 3)      0           main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12)           0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 12)           0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 12)           0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "x_m0 (Dense)                    (None, 40)           520         flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "x_m1 (Dense)                    (None, 40)           520         flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "x_m2 (Dense)                    (None, 40)           520         flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "x_s0 (Dense)                    (None, 40)           520         flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "x_s1 (Dense)                    (None, 40)           520         flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "x_s2 (Dense)                    (None, 40)           520         flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 40)           0           x_m0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 40)           0           x_m1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 40)           0           x_m2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 40)           0           x_s0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 40)           0           x_s1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 40)           0           x_s2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 2, 2, 3)      0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 2, 2, 3)      0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 2, 2, 3)      0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 2, 2, 10)     0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 2, 2, 10)     0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 2, 2, 10)     0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 2, 2, 10)     0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 2, 2, 10)     0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 2, 2, 10)     0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "weights0 (LocallyConnected2D)   (None, 2, 2, 10)     160         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "weights1 (LocallyConnected2D)   (None, 2, 2, 10)     160         reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "weights2 (LocallyConnected2D)   (None, 2, 2, 10)     160         reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 2, 30)     0           reshape_1[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2, 2, 30)     0           reshape_2[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2, 2, 30)     0           weights0[0][0]                   \n",
      "                                                                 weights1[0][0]                   \n",
      "                                                                 weights2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 2, 2, 90)     0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,600\n",
      "Trainable params: 3,600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Building model...\")\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=main_output)\n",
    "model.compile(optimizer=optimizer, loss=lambda x, y: pixelcnn_loss(x, y, img_rows, img_cols, img_chns, n_components))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:52:19.849126Z",
     "start_time": "2019-05-13T12:52:13.395930Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180c20a7d743405a80a7da7b07fafb66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68028c409334c118d122b30c98baed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(1, 12), b.shape=(12, 40), m=1, n=40, k=12\n\t [[{{node x_s0/MatMul}} = MatMul[T=DT_FLOAT, _class=[\"loc:@training/RMSprop/gradients/x_s0/MatMul_grad/MatMul_1\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](flatten_1/Reshape, x_s0/kernel/read)]]\n\t [[{{node loss/mul/_123}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1626_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d40c4629ee26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTQDMNotebookCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#validation_data=(X_train, X_train),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(1, 12), b.shape=(12, 40), m=1, n=40, k=12\n\t [[{{node x_s0/MatMul}} = MatMul[T=DT_FLOAT, _class=[\"loc:@training/RMSprop/gradients/x_s0/MatMul_grad/MatMul_1\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](flatten_1/Reshape, x_s0/kernel/read)]]\n\t [[{{node loss/mul/_123}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1626_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping('loss', min_delta=1.0, patience=5)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, min_lr=0.0001)\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir='./logs_test_loss_mixture/base', histogram_freq=1, batch_size=1, write_graph=True, \n",
    "                                          write_grads=True, write_images=True, update_freq='batch')\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, X_train,\n",
    "    batch_size=batch_size,\n",
    "    #epochs=epochs,\n",
    "    epochs=40,\n",
    "    callbacks=[TQDMNotebookCallback(), early_stopping, reduce_lr],\n",
    "    #validation_data=(X_train, X_train),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "done = time.time()\n",
    "elapsed = done - start\n",
    "print(\"Elapsed: \", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:52:19.850001Z",
     "start_time": "2019-05-13T12:52:10.350Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "display(df.describe(percentiles=[0.25 * i for i in range(4)] + [0.95, 0.99]))\n",
    "df['loss'].plot(figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:52:19.850908Z",
     "start_time": "2019-05-13T12:52:10.354Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "lossvals = model.evaluate(X_train, X_train)\n",
    "print(lossvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Some Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:52:19.851541Z",
     "start_time": "2019-05-13T12:52:10.359Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "debug = True\n",
    "\n",
    "def gen_image(model, num_samples=batch_size):\n",
    "    x_sample = np.zeros((num_samples, img_rows, img_cols, img_chns))\n",
    "    \n",
    "    # Iteratively generate each conditional pixel P(x_i | x_{1,..,i-1})\n",
    "    for i in range(img_rows):\n",
    "        for j in range(img_cols):\n",
    "            for k in range(img_chns):\n",
    "                x_out = model.predict(x_sample, num_samples)\n",
    "                for n in range(num_samples):\n",
    "                    offset = k * n_components\n",
    "                    x_ms = x_out[n, i, j, offset:offset + n_components]\n",
    "                    offset = n_components * img_chns + k * n_components\n",
    "                    x_invs = x_out[n, i, j, offset:offset + n_components]\n",
    "                    offset = 2 * n_components * img_chns + k * n_components\n",
    "                    weights = softmax(x_out[n, i, j, offset:offset + n_components])\n",
    "                    pvals = compute_mixture(x_ms, x_invs, weights, n_components)\n",
    "                    pvals /= (np.sum(pvals) + 1e-5)\n",
    "                    pixel_val = np.argmax(np.random.multinomial(1, pvals))\n",
    "                    x_sample[n, i, j, k] = pixel_val / 255.\n",
    "                    if 0 <= i <= 1 and 0 <= j <= 1 and debug:\n",
    "                        print(\"====\", i, j, k)\n",
    "                        print(\" m: \", x_ms)\n",
    "                        print(\" param_m: \", (params[0][i, j, k] - 127.5) / 127.5)\n",
    "                        print(\" E[m]: \", (x_ms * weights).sum())\n",
    "                        print(\" invs: \", x_invs)\n",
    "                        print(\" param_invs: \", np.log(127.5 / params[1][i, j, k]))\n",
    "                        print(\" weights: \", weights)\n",
    "                        print(\" param_weight: \", params[2][i, j, k])\n",
    "                        s = pd.Series(pvals)\n",
    "                        print(\" pvals: \", s[s>1e-2])\n",
    "                        print(\" pixel_val: \", pixel_val)\n",
    "                        #print(\" x_out[n, i, j, :]: \", x_out[n, i, j, :])\n",
    "                        #print(\" x_out: \", x_out)\n",
    "                        #print(\" sample_val: \", x_sample[n, i, j, k])\n",
    "                        #assert False\n",
    "        if debug:\n",
    "            print(\"row\", i)\n",
    "                \n",
    "    return x_sample\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "n = 1 if debug else 10\n",
    "figure = np.zeros((img_rows * ((n - 1) // 10 + 1), img_cols * n, img_chns))\n",
    "print(figure.shape)\n",
    "for i in range(n):\n",
    "    samples = gen_image(model)\n",
    "    for j in range(batch_size):\n",
    "        img = samples[j] \n",
    "        d_x = ((i * batch_size + j) // 10) * img_rows\n",
    "        d_y = ((i * batch_size + j) % 10) * img_cols\n",
    "        figure[d_x:d_x + img_rows, d_y:d_y + img_cols, :] = img\n",
    "        \n",
    "print(\"Generated: \", elapsed)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(figure)\n",
    "plt.show()\n",
    "\n",
    "print(\"Orig: \")\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(orig_img)\n",
    "plt.show()\n",
    "\n",
    "done = time.time()\n",
    "elapsed = done - start\n",
    "print(\"Elapsed: \", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validatation\n",
    "\n",
    "Check that we were able to approximately recover the original distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-13T12:52:19.852145Z",
     "start_time": "2019-05-13T12:52:10.363Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "# Generated params \n",
    "x_sample = np.zeros((num_samples, img_rows, img_cols, img_chns))\n",
    "x_out = model.predict(x_sample, num_samples)\n",
    "\n",
    "for i in range(img_cols):\n",
    "    for j in range(img_rows):\n",
    "        fig = plt.figure(figsize=(10,8), )\n",
    "        fig.suptitle(\"pixel (%d, %d)\" % (i, j), fontsize=16)\n",
    "        for k in range(img_chns):\n",
    "            ax = plt.subplot(img_chns, 1, k + 1)\n",
    "            \n",
    "            # Orig params\n",
    "            ms = (params[0][i, j, k, :] - 127.5)  / 127.5\n",
    "            invss = np.log(127.5 / params[1][i, j, k, :])\n",
    "            weights = params[2][i, j, k, :]\n",
    "            \n",
    "            pvals_orig = compute_mixture(ms, invss, weights, n_comps=2)\n",
    "            print(ms, invss, weights)\n",
    "            pvals_orig /= pvals_orig.sum()\n",
    "            samples = pd.Series(np.random.choice(len(pvals_orig), N, p=pvals_orig))\n",
    "            samples.hist(bins=128, ax=ax, alpha=0.5, label='orig')\n",
    "            \n",
    "            # Generated params\n",
    "            offset = k * n_components\n",
    "            ms = x_out[n, i, j, offset:offset + n_components]\n",
    "            offset = n_components * img_chns + k * n_components\n",
    "            invss = x_out[n, i, j, offset:offset + n_components]\n",
    "            offset = 2 * n_components * img_chns + k * n_components\n",
    "            weights = softmax(x_out[n, i, j, offset:offset + n_components])\n",
    "            \n",
    "            pvals_gen = compute_mixture(ms, invss, weights, n_components)\n",
    "            print(ms, invss, weights)\n",
    "            pvals_gen /= pvals_gen.sum()\n",
    "            samples = pd.Series(np.random.choice(len(pvals_gen), N, p=pvals_gen))\n",
    "            samples.hist(bins=128, ax=ax, alpha=0.5, label='generated')\n",
    "            \n",
    "            ax.legend()\n",
    "            print('KL Divergence(orig, gen) for (%d,%d,%d): %.2f' % (i, j, k, scipy.stats.entropy(pvals_orig, pvals_gen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Notes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019-03-03\n",
    "\n",
    "Issues:\n",
    "    \n",
    "* Wrong order of RGB slices when repeating image\n",
    "* Used old 255. value vs. 127.5\n",
    "* Added non-zero init to param values\n",
    "    \n",
    "Next TODO:\n",
    "\n",
    "* Plot histograms of 0 to 255 pixel values, somehow see that the mass is the same?\n",
    "* Maybe KL divergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019-03-07\n",
    "\n",
    " * It looks like my generated distributions are spreading too much mass over the range, which might be because I'm allowing the \"invs\" param to be small (< 1), which will naturally spread it very wide.  The model probably gets confused in these situations and finds a local minima that spreads it wide instead of using the power of the mixtures.  Maybe try to constrain it a bit more?\n",
    " \n",
    "<img src=\"images/2019-03-07-spread.png\">\n",
    "\n",
    " * Tried to make \"invs\" to be in range (2, 7), but it looks like it made the spreading worse.  It looks like these bimodal distributions aren't using the weights properly.  Maybe I need to debug my loss function?  The mixture maybe aren't being taken into account properly?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019-03-25\n",
    "\n",
    "Issues:\n",
    "\n",
    "* Made minimum invss = 2.0 (by using `+2` in Lambda) so that we don't get distributions that are too diffuse\n",
    "* Made weights initialized all at (1's) to get a more even spread\n",
    "\n",
    "\n",
    "Comments:\n",
    "\n",
    "<img src=\"images/2019-03-25-spread.png\">\n",
    "\n",
    "* I have a feeling that we can't recover the weights easily sometimes because the initalized weights (glorat_uniform) converges to a weird local minumum.  Makes sense b/c mixutre models in general won't converge to a global minimum through gradient descent.\n",
    "    * Take a look at diagram: For the \"G\", \"B\" pixels, one of the mixtures looks pretty close, while the other isn't too bad (the \"m\" is too far to the left, so all the mass gets to the \"0\" pixel).  \n",
    "    * However, for the \"R\" histogram, it converged to some bad local minima. You can see the mass is spread out so far.  The weight distribution is (0.95, 0.05) and the m is around (0.41,0.47) (in the middle).  This probably means that we found a local minima but it doesn't at all match the true distribution.\n",
    "* Interesting, loss goes down to (27-ish) but KL diverge is relatively big for the distributions.  Makes sense since I'm not optimizing for KL divergence (in real life I have no idea what the distributions are.\n",
    "\n",
    "Next TODO:\n",
    "\n",
    "* Assuming that I can't converge to a global minimum (b/c of SGD doesn't allow it), maybe what I need is to have *over-capacity* (i.e. more mixture components) so I can find a good local minima that better approximates what I want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-04-28\n",
    "\n",
    "Finally found some time to work on it...\n",
    "\n",
    "* Found a bug!  In the loss function, I was still using protection limits of [0.001, 0.999] but I rescaled things so it really should have been [-0.999, 0.999]\n",
    "* I played around with different number of mixture components (while the source dataset still has 2 components) and I was right!  With only 2 components it's hard to model 2 components, but at 4/5, it gets pretty close (5 components):\n",
    "\n",
    "<img src=\"images/2019-04-28-spread1.png\">\n",
    "\n",
    "However, the one pixel that has values that are closer together doesn't quite match:\n",
    "\n",
    "\n",
    "<img src=\"images/2019-04-28-spread2.png\">\n",
    "\n",
    "Increasing the components to 10 seems to solve it:\n",
    "\n",
    "<img src=\"images/2019-04-28-spread3-10comps.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {
    "042d9353a5294a1cae93f8eb9e9a3c84": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "05e25527c52843438585a66b7e9f443c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "06fdc638a3dc45a0a1e82f2b3c90c18d": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "07f49ab2133c40a4a245e0a348843084": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "12369f27c46c46f58c925a3d9749e65d": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "16bcb109a6814007801cf814c76aa6d3": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "1930a5477ce44850aaa99c20f3f7e542": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "194b186d11d94c28afd8a01d9fd8ae1e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "1ccc61b6a278489eacb5735a740e79bf": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "1d67ae6836244a81bff253e0426488ff": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "213bd5ec7a124467b85e240c7bdcc819": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "23c591bc3a7e4df5b0e21677e2869f27": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "24382361c62a4bbc9741c2129be71810": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "24419d69ef3347819fcc70448978bf05": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "25ecd0ca842e43fcabc04a82fff2dac1": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "26bab0144edd46609ddcdd6bfd65115f": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "28707906c2344d00b07ee40c479121db": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "287646592b8e41f2920e73c7e92d2ec0": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "28a8916064514ce7912c103e7370ad47": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "2a100dade8384007bf4abf580068cdc3": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "2b28c9ea3e5b4950bdfcd897162bd56d": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "2b5b08661aee4f9296e0878cb4ce041b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "2bd96fa1931842749cd9ba68345a4132": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "32a97da73a594458a7080928d0aa12a4": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "33a124f13a124b64bbca8a0a4a96999c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "3477d40608834aca90d0f57b44f7b3e7": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "357ae9996a19410e98f131fc86e2c937": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "3a1b2c52257843549c64aedde0be827c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "3a685442e38243f5a601d54d59c37fdd": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "3ac750287e394cc281f1dc3487e94df6": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "3afef162a0304210973a3797acf40cab": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "3c47ecdd65c049cfa66eb21ad8fd933b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "40b3e13fb5ae4ceda47aa8542106d365": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "439afcda2d4e4ce9af1ea7024a9bd0b5": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "440c8e7f865840019dd96476fe5fe1bc": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "4480a3d377a748c5bbd202d71b80b323": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "4692e78886d942c982ddd2a97a55f649": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "47282faa187746bb8339a4fb4ac58068": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "4a1af9ac778a45d8baac52255b6aaac0": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "4a7ca0764c1d4f4e8c818452e0faad22": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "4f9ead92babf43a6a7c2dbe03bc199e1": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "4fe4e6c7a7c04da0b82eedfee59f123c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "509696b56ebd4c078824720adfb9c882": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "5288b8c03d57497384001bd545f9473a": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "54c0486d9d194fd89a425f8bfe8abffd": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "5591146f394445e9a7562bfbeba3b210": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "569e07a8c03b417a8bec640521c1e8d8": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "56d382118cbe49f09c5518839d1309ee": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "58879c6ef3904577a0d0ca261361d888": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "59de165a886a4dcd855ec33e4682bd2d": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "5d835fe3d36c41d9b140f25c874e02e7": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "5dcb1825f8f945509c1521456ec8802f": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "5fc113b88db343038e6190f2e2e1df1e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "601e0344661243299a2a6d382458f93a": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "6060d310a5e34896a7156115cc6c3b43": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "607439f270cb405cad0280cd5bf035bf": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "695d75c78b7148a4a7c84d57bed02c35": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "6b76037650064c71afc1ef43cea3b884": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "6ec89ae257604fa0a672b9c0042d1c53": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "70dfa87054284e3d84cd08df8bfbf705": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "70fefa448a124b56bec948f54c0fe1fc": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "73deeee41eb04b1c9b5d12164159f500": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "74df7b1ee69449e6a6733da633e4c583": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "75c980fe55484a15b5fadf86960e6984": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "770dfa1b77ed46258fd936b4a5b002f7": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "79b014c35bb64afd98775e32a56c8469": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "7b97837f50464a0194b38acd2ee83d07": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "7df60277eba44da5acc4ae70299cd1db": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "7e9f3f789dd9472189a557183640b7c9": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "7eb10ea82e954391a3733334c4276916": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "7fe51828fd9745e9bad8a4632d35a137": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "807fe4bc5122427a8d991815a0afdefe": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "82b2dfaaeca94ac7871eb714ebf0bd24": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "83eb650f527a42e9a904a1dc3489226e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "84c3b92deb524251aae620eb42b81d57": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "85ca8ba9ed1c4fc1bd9f636d4efb13a2": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "8a803cf98b4a4ad38b46389cd0cbc624": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "8f271df026484a06be2f6509462c42ed": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "8f2d4f8192c4455a922e9f4f4388b10a": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "99722895709c48d7baca4359ce30f165": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "9994b42dd71f4dcb8412076e04f74af1": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "9c65331cb7044f07bea6f1dcd02be34e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "9d93b50dddb843ffb3192fa7463d1eb3": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "9ddcff6b73e84b71bb72cbaf509b6d7d": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "9ff602ebdfe446f8a7973c18b0b9c448": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "a13b7297bcfd48aeb1f6adeb79c6907e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "a2d8253207ff47c196ec18d0c3e292fc": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "a447bd0d14cf402b844ccef55b5e2d6e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "a8fd29c4d7474543bfb283fe1bc22752": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "a938e8c6d6f54d119dc4e0fc6591ceb2": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "abb7603ed5cc4ea7a3e9133abc83daab": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "abd62c0bee8d4a1d93a95b31b9aaf486": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "ac5eaac0d0bc4bdc899be9b7c7609004": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "ac8d814446504f1fb7359e84efc877df": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "aecfd70ffbbb491296ddfead5c3e676c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "b012c12df7ec4de5bee68e9f10c67227": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "b0413da85a834535bf0910a1a2049cf4": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "b3e05cfa4dfb44e8aec6501b481e740a": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "b8e7a6d97abc49eb8b24af81997c814b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "b958fd557b674353b4513a1223d1a451": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "bc39a43c23b9496fb53533370e7f076b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "bcb5c68f5f9640ffbc0d14af2a8d2609": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "c1a529e546e84cfe858abc405448a31c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "c51f1c60f93c4707808116607aceb523": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "c6cefa23028c47d1a9b8e34f2173662b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "c867ce48830d48ff838c535f911cde38": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "cc1c3c0a394049c7817525d4c0dbc660": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "ce61c3f1b09d4b7aaaa04b999968853b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "ced5cb09460b44f2b3cb07cd26ba2d80": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "d0a64a823a4649898b5ef2ae2f1bbe27": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "d2307dd3ea50414580c68a01944b6609": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "d73036ff5b9a463aa2d560cc98e09a99": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "d8bff5fe3809457696452bd7d37b0163": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "da29d43a5fbd4d0db082c70348e5783e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "dcbbfefe63b849b29b2c6f2c445f9d44": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "de65778ccbf74269a7aecafe0f4a84e9": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "e2f426df16ea437cb3eb19a6e29718d3": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "e331ecdfb1034be78954606b29282291": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "e57c668870b044aab6fb89a073374887": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "e7d90b37142d4468a9a3f88fe5e7ebe5": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "e7dfb79db2074d32b546b0f5b35d037a": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "ea7dc8f6b6904a098cc8bcd3cccb0f09": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "ead95701b3c948fe810264c9f916c701": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "ec1f20b0a9a848a785617463aed63555": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "ef7271ab301c4d52b331707746f9638e": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "f057baa922394139936146319110c770": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "f07a509b915040e08e37ababd37b7cf1": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "f259740c24a24bb3a309aec954f66fe3": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "f612f1c9698d4be4bb42c2f0e2c69108": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "f6efb652598c41549a9f19b2f9ceff2b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "f97ed4db90d24d88a228ac1e52375a0c": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "fd43e083f58d43a68688581cdf48acab": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "fda46d318b0941c19dfe61eb3e02cb23": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    },
    "fe6b5b3475984be890e4e11f3e5d3ef1": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
