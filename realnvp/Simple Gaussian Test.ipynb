{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T12:56:12.720118Z",
     "start_time": "2020-04-20T12:56:10.867942Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import logit\n",
    "from IPython.display import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, Layer,\n",
    "                                     Activation, Dropout, Conv2D, Conv2DTranspose,\n",
    "                                     Concatenate, add, Add, Multiply)\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow_addons.callbacks import TQDMProgressBar\n",
    "\n",
    "from realnvp_helpers import Mask, FlowBatchNorm\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T12:56:12.728840Z",
     "start_time": "2020-04-20T12:56:12.721949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4, 4, 3)\n",
      "(100, 4, 4, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 4.78335220e+00, -2.42847947e-01, -4.56495054e+00],\n",
       "        [ 1.34196685e+00,  3.59085666e-02,  2.02109569e+00],\n",
       "        [-1.48355374e+00, -5.27993436e+00,  1.63540859e+00],\n",
       "        [ 2.20682244e+00, -1.72888289e+00, -1.50962402e+00]],\n",
       "\n",
       "       [[-4.32964058e-02,  7.23833589e-01, -3.27654379e+00],\n",
       "        [ 3.72209104e+00,  3.88318914e+00,  2.41773134e+00],\n",
       "        [ 1.05856290e+00, -2.09207141e-01, -2.32643143e-01],\n",
       "        [-1.64951105e+00, -1.55208218e-03, -9.09904779e-01]],\n",
       "\n",
       "       [[ 3.57437264e+00, -5.45591848e-01, -1.69284413e+00],\n",
       "        [-4.42920878e-01,  7.48242203e+00,  2.06824914e+00],\n",
       "        [-6.83922703e-01, -9.15977974e-01,  3.87194158e-01],\n",
       "        [ 8.70215626e-01,  4.74251878e+00,  7.39651785e-01]],\n",
       "\n",
       "       [[-3.81738878e+00,  1.30620185e-01, -2.36377810e+00],\n",
       "        [ 3.18944156e+00,  4.78349893e+00, -2.99523246e-02],\n",
       "        [-3.49352233e+00,  4.18314967e+00,  8.42404793e-01],\n",
       "        [-4.79695579e+00,  2.22658691e+00, -1.29911978e+00]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "shape = (4, 4, 3)\n",
    "batch_shape = (batch_size,) + shape\n",
    "samples = 100\n",
    "\n",
    "train_data = np.random.normal(0.5, 3, size=(samples,) + (shape))\n",
    "print(batch_shape)\n",
    "print(train_data.shape)\n",
    "train_data[0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T12:56:12.825171Z",
     "start_time": "2020-04-20T12:56:12.730785Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_block(input_shape, kernel_size, filters, stage, block, use_resid=True):\n",
    "    ''' Adapted from resnet50 implementation in Keras '''\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    input_tensor = Input(batch_shape=input_shape)\n",
    "    x = Conv2D(filters1, (1, 1),\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    if use_resid:\n",
    "        x = add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return Model(input_tensor, x, name='conv_block' + stage + block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T12:56:12.937878Z",
     "start_time": "2020-04-20T12:56:12.828788Z"
    }
   },
   "outputs": [],
   "source": [
    "def coupling_layer(input_shape, mask_type, stage):\n",
    "    ''' Implements (as per paper):\n",
    "        y = b * x + (1 - b) * [x * exp(s(b * x)) + t(b * x)]\n",
    "    '''\n",
    "    assert mask_type in ['check_even', 'check_odd', 'channel_even', 'channel_odd']\n",
    "    mask_prefix = 'check' if mask_type.startswith('check') else 'channel'\n",
    "    mask_opposite = 'odd' if mask_type.endswith('even') else 'even'\n",
    "    \n",
    "    input_tensor = Input(batch_shape=input_shape)\n",
    "    \n",
    "    # Raw operations for step\n",
    "    b0 = Mask(mask_type)\n",
    "    b1 = Mask(mask_prefix + '_' + mask_opposite)\n",
    "    s_ = conv_block(input_shape, (3, 3), (32, 32, 3), stage, '_s', use_resid=True)\n",
    "    t_ = conv_block(input_shape, (3, 3), (32, 32, 3), stage, '_t', use_resid=True)\n",
    "    batch = FlowBatchNorm(name='_'.join(['FlowBatchNorm' + mask_type + stage]))\n",
    "       \n",
    "    # Forward\n",
    "    masked_input = b1(input_tensor)\n",
    "    s = s_(masked_input)\n",
    "    t = t_(masked_input)\n",
    "    coupling = Lambda(lambda ins:  ins[0] * K.exp(ins[1]) + ins[2])([input_tensor, s, t])\n",
    "    coupling_mask = b0(coupling)\n",
    "    out1, out2 = Add()([masked_input, coupling_mask]), b0(s)\n",
    "    out1_norm = batch(out1)\n",
    "    #batch_loss = Lambda(lambda x: - (K.log(gamma) - 0.5 * K.log(x + batch.epsilon)))(var)\n",
    "    #batch_loss = Lambda(lambda x: -K.log(gamma))(var)\n",
    "    #batch_loss = Lambda(lambda x: - ( - 0.5 * K.log(x + batch.epsilon)))(var)\n",
    "    \n",
    "    # Reverse\n",
    "   \n",
    "    # Return result + masked scale for loss function\n",
    "    return Model(input_tensor, [out1_norm, out2], name='_'.join(['coupling', mask_type, stage]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T12:56:13.046841Z",
     "start_time": "2020-04-20T12:56:12.939774Z"
    }
   },
   "outputs": [],
   "source": [
    "def coupling_group(input_tensor, steps, mask_type, stage):\n",
    "    name_mapping = dict(enumerate(string.ascii_lowercase))\n",
    "    \n",
    "    # TODO: Only need check/channel, not even/odd right?\n",
    "    assert mask_type in ['check_even', 'check_odd', 'channel_even', 'channel_odd']\n",
    "    mask_prefix = 'check' if mask_type.startswith('check') else 'channel'\n",
    "    \n",
    "    x = input_tensor\n",
    "    s_losses = []\n",
    "    batch_losses = []\n",
    "    for i in range(3):\n",
    "        mask_type = mask_prefix + ('_even' if i % 2 == 0 else '_odd')\n",
    "        step = coupling_layer(input_tensor.shape, mask_type, stage=str(stage) + name_mapping[i])\n",
    "        x, s = step(x)\n",
    "        #x, s = step(x)\n",
    "        s_losses.append(s)\n",
    "    \n",
    "    return x, s_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T12:56:13.163717Z",
     "start_time": "2020-04-20T12:56:13.049508Z"
    }
   },
   "outputs": [],
   "source": [
    "def realnvp_zloss(target, z):\n",
    "    # log(p_X(x)) = log(p_Z(f(x))) + log(|det(\\partial f(x) / \\partial X^T)|)\n",
    "    # Prior is standard normal(mu=0, sigma=1)\n",
    "    shape = z.shape\n",
    "    return K.sum(-0.5 * np.log(math.pi) - 0.5 * z**2, axis=list(range(1, len(shape[1:]))))\n",
    "\n",
    "def const_loss(target, output):\n",
    "    # For debugging\n",
    "    return K.constant(0)\n",
    "\n",
    "def realnvp_sumloss(target, output):\n",
    "    # Determinant is just sum of \"s\" or \"batch loss\" params (already log-space)\n",
    "    shape = output.shape\n",
    "    return K.sum(output, axis=list(range(1, len(shape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T12:56:15.651706Z",
     "start_time": "2020-04-20T12:56:13.165789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(10, 4, 4, 3)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coupling_check_even_a0 (Model)  [(10, 4, 4, 3), (10, 19498       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "s_losses (Concatenate)          (10, 4, 4, 6)        0           coupling_check_even_a0[1][1]     \n",
      "                                                                 coupling_check_even_a0[1][1]     \n",
      "==================================================================================================\n",
      "Total params: 19,498\n",
      "Trainable params: 19,224\n",
      "Non-trainable params: 274\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(batch_shape=batch_shape)\n",
    "#x = conv_block(shape, (3, 3), (32, 32, 3), '0', '_s', use_resid=True)(input_tensor)\n",
    "step = coupling_layer(batch_shape, 'check_even', stage=str('a') + '0')\n",
    "x, s = step(input_tensor)\n",
    "s_losses = [s, s]\n",
    "\n",
    "#x, s_losses, batch_losses = coupling_group(input_tensor, steps=3, mask_type='check_even', stage=1)\n",
    "s_losses = Concatenate(name='s_losses')(s_losses)\n",
    "\n",
    "forward_model = Model(inputs=input_tensor, outputs=[x, s_losses])\n",
    "optimizer = Adam(lr=0.001)\n",
    "forward_model.compile(optimizer=optimizer, \n",
    "                      loss=[realnvp_zloss, realnvp_sumloss])\n",
    "                      #loss=[const_loss, const_loss, realnvp_sumloss])\n",
    "forward_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T12:56:15.663945Z",
     "start_time": "2020-04-20T12:56:15.653483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_losses_from_layers(layers):\n",
    "    losses = []\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, Model):\n",
    "            losses.extend(layer._losses)\n",
    "            losses.extend(get_losses_from_layers(layer.layers))\n",
    "        else:\n",
    "            losses.extend(layer.losses)\n",
    "    return losses\n",
    "\n",
    "get_losses_from_layers(forward_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T12:56:35.896867Z",
     "start_time": "2020-04-20T12:56:32.300195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4217b9bc2814b32bbb56fc640fff56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', layout=Layout(flex='2'), max=20.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d47d002a194cfd9037b9cdfeebc5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d67d80caed4135abc1e76fde250bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3cf3c110344ef0bb4f22b15f2e104f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40e727c58b143b3aed4bac7d071acf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daad9c6e0a484b93bafbbbcc5862fba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e317c7897a4b40a9a7c96fe551184a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06cd7cdf84244145944f8c5b55fd707c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24b5e81bcf246c8b79d9372f2db857b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748fcf1fab5b4311896071762a2cc164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52ec345f0a84a6a8468611fcf1786af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c6facc26a24e85af9317fce737a34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8e1937d9034f108e9ad56513e835cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c070dffbc54090844e285be23231c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67fc8b7582e4218a6795d5b6a3b78e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8179d499b643f0bc02db0874917c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0152970c25fe4295868304a80b5dd47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f1e5777f9e42118f49b0317c83e968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4f6d32d228438cbc2b195ef0ac4ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0776c557554eb1ac17c4ef9a7c4e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88dc86248dc64eff912374249b24612e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#early_stopping = keras.callbacks.EarlyStopping('val_loss', min_delta=50.0, patience=5)\n",
    "#reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001)\n",
    "s = [len(train_data)] + [int(x) for x in s_losses.shape[1:]]\n",
    "#s[0] = int(train_data.shape[0])\n",
    "#print(train_data.shape, np.zeros(s).shape)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='graph', \n",
    "                          batch_size=batch_size, \n",
    "                          histogram_freq=1, \n",
    "                          write_graph=True) \n",
    "history = forward_model.fit(\n",
    "    train_data, [train_data, np.zeros(s)],\n",
    "    #validation_data=(train_data[:10], [train_data[:10], np.zeros(s)[:10], np.zeros(s)[:10]]),\n",
    "    batch_size=batch_size,\n",
    "    epochs=20,\n",
    "    callbacks=[TQDMProgressBar()], #, tensorboard], #, early_stopping, reduce_lr],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T12:56:40.971026Z",
     "start_time": "2020-04-20T12:56:40.411622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>coupling_check_even_a0_loss</th>\n",
       "      <th>s_losses_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.336507</td>\n",
       "      <td>-17.229502</td>\n",
       "      <td>7.892995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.082047</td>\n",
       "      <td>-17.392105</td>\n",
       "      <td>0.310059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-17.555961</td>\n",
       "      <td>-17.559040</td>\n",
       "      <td>0.003081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-17.730081</td>\n",
       "      <td>-17.731003</td>\n",
       "      <td>0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.908669</td>\n",
       "      <td>-17.908670</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-18.092261</td>\n",
       "      <td>-18.092548</td>\n",
       "      <td>0.000288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-18.282982</td>\n",
       "      <td>-18.282982</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-18.479388</td>\n",
       "      <td>-18.480188</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-18.684305</td>\n",
       "      <td>-18.684303</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-18.895439</td>\n",
       "      <td>-18.895437</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-19.113634</td>\n",
       "      <td>-19.113636</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-19.338562</td>\n",
       "      <td>-19.338947</td>\n",
       "      <td>0.000386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-19.571400</td>\n",
       "      <td>-19.571400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-19.811002</td>\n",
       "      <td>-19.811001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-20.057763</td>\n",
       "      <td>-20.057762</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-20.311692</td>\n",
       "      <td>-20.311691</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-20.572778</td>\n",
       "      <td>-20.572779</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-20.841031</td>\n",
       "      <td>-20.841030</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-21.116434</td>\n",
       "      <td>-21.116434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-21.398993</td>\n",
       "      <td>-21.398993</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  coupling_check_even_a0_loss  s_losses_loss\n",
       "0   -9.336507                   -17.229502       7.892995\n",
       "1  -17.082047                   -17.392105       0.310059\n",
       "2  -17.555961                   -17.559040       0.003081\n",
       "3  -17.730081                   -17.731003       0.000920\n",
       "4  -17.908669                   -17.908670       0.000000\n",
       "5  -18.092261                   -18.092548       0.000288\n",
       "6  -18.282982                   -18.282982       0.000000\n",
       "7  -18.479388                   -18.480188       0.000800\n",
       "8  -18.684305                   -18.684303       0.000000\n",
       "9  -18.895439                   -18.895437       0.000000\n",
       "10 -19.113634                   -19.113636       0.000000\n",
       "11 -19.338562                   -19.338947       0.000386\n",
       "12 -19.571400                   -19.571400       0.000000\n",
       "13 -19.811002                   -19.811001       0.000000\n",
       "14 -20.057763                   -20.057762       0.000000\n",
       "15 -20.311692                   -20.311691       0.000000\n",
       "16 -20.572778                   -20.572779       0.000000\n",
       "17 -20.841031                   -20.841030       0.000000\n",
       "18 -21.116434                   -21.116434       0.000000\n",
       "19 -21.398993                   -21.398993       0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0c20497198>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "#display(df.describe(percentiles=[0.25 * i for i in range(4)] + [0.95, 0.99]))\n",
    "col = 'val_loss' if 'val_loss' in df else 'loss'\n",
    "display(df[-25:])\n",
    "df[col][-25:].plot(figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-07-28\n",
    "\n",
    "* Got some framework up to do coupling layers but having trouble passing the scale parameter to the loss function, getting some weird tensorflow error, needs more debugging\n",
    "* Without the determinant in the loss function, it looks like loss goes down, so maybe on the right track?\n",
    "    * It's actually weird that we're not using the image in the output, but I guess that's what's great about this reversible model!\n",
    "* TODO:\n",
    "    * Debug scale function in loss\n",
    "    * Add reverse (generator) network to functions above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-07-29\n",
    "\n",
    "* Explanation of how to estimate probability of continuous variables (relevant for computing bits/pixel without an explicit discrete distribution): https://math.stackexchange.com/questions/2818318/probability-that-a-sample-is-generated-from-a-distribution\n",
    "* Idea for a post, explain likelihood estimation of discrete vs. continuous distributions (like pixels), include:\n",
    "  * Probability of observing a value from continuous distribution = 0\n",
    "     * https://math.stackexchange.com/questions/2818318/probability-that-a-sample-is-generated-from-a-distribution\n",
    "  * Probability of observing a value from a set of discrete hypthesis (models) is non-zero using epsilon trick (see above link):\n",
    "     * https://math.stackexchange.com/questions/920241/can-an-observed-event-in-fact-be-of-zero-probability\n",
    "  * Explain Equation 3 from \"A NOTE ON THE EVALUATION OF GENERATIVE MODELS\"\n",
    "     * Also include an example using a simpler case, like a bernoulli variable that we're estimating using a continuous distribution\n",
    "  * Bring it back to modelling pixels and how they usually do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-03-30\n",
    "\n",
    "* To make reversible network, build forward and backward network at the same time using `Model()` to have components that I can use in both networks\n",
    "* Looks like I have some instability here, depending on the run I can get an exact fit (-100s loss) or a poor a fit (+10):\n",
    "    * Turning off residual networks helps\n",
    "    * Adjusting the learning rate, batch size helps but hard to pinpoint a methodology\n",
    "* Most likely it's the instability of using a scale parameter (RealNVP paper Section 3.7), might need to implement their batch norm for more stable results, especially when adding more layers:\n",
    "    * Reimplement `BatchNorm`: https://github.com/keras-team/keras/blob/master/keras/layers/normalization.py\n",
    "    * Except return regular result AND (variance + eps) term\n",
    "    * Use the (var + eps) term to compute Jacobian for loss function (should just be log-additive)\n",
    "* Once this is done, add back the other stuff:\n",
    "    * Turn on residual shortcuts\n",
    "    * Change batch size to reasonable number and learning rate=0.01\n",
    "* If this still doesn't work, might want to implement \"Running average over recent minibatches\" in Appendix E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-03-31\n",
    "\n",
    "* Fixed a bug (I think) in the network where the coupling layer was wrong.  However, it still sometimes get stuck at around a loss of 5 but more often than not (on another training run) get to -10 (after 20 iters).\n",
    "* Trying to get FlowBatchNorm worknig but having some issues passing the determinant batch loss as an output because the `batch_size` is not getting passed (it has dimension (3,) but should have dimension (None, 3)).  Need to figure out how to tranlate a tensor to Layer that includes batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-04-05\n",
    "\n",
    "* Reminder: BatchNormalization on conv layers only need to normalize across [B, W, H, :] layers, not the \"C\" layer because the filter is identical across a channel (so it uses the same mean/var to normalize).  This is nice because it's the same axis (-1) you would normalize across in a Dense layer. See: https://intellipaat.com/community/3872/batch-normalization-in-convolutional-neural-network\n",
    "* I think I figured out how to return the batchnorm weights back but now I'm hitting a roadblock when I try to merge them together to put as part of the output loss -- maybe I should just forget it and use the tensors directly in the output loss?\n",
    "* Now that I switched to an explicit batch size, it doesn't run anymore... get this error \"Incompatible shapes: [4] vs. [32]\", probably some assumption that I had, got to work backwards and fix it I think.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-04-14\n",
    "\n",
    "* Okay figured out the weird error I was getting: when a Keras model has multiple outputs you either have to give it a list or dict of loss functions, otherwise it will apply the same loss to each output!  Of course, I just assumed that it gives you all outputs in one loss function. So silly!\n",
    "* I reverted the change to explicitly set batch. Instead in the `BatchNormFlow` layer I just multiply zero by the `inputs` and then add the mean/variance.  I think this gives the right shape?\n",
    "* **TODOs**:\n",
    "  * Check that shape/computation for `BatchNormFlow`/`batch_losses` loss is correct\n",
    "  * Check that loss functions are actually returning a negative log-loss (not just the log)\n",
    "  * Validate the model is fitting what I want (right now I have an elbow effect as I train more) -- should there be backprop through the batch_losses? I guess not?  Check the paper and figure out what to do.\n",
    "  * Add back in the bigger model that has multiple coupling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-04-15\n",
    "\n",
    "* Somehow I suspect that the batch loss is not getting optimized (the var parameter in the batch norm function).  When I set the other loss components to zero, I see that hte batch loss is not really getting smaller -- should it?\n",
    "\n",
    "        loss \tcoupling_check_even_1c_loss \ts_losses_loss \tbatch_losses_loss\n",
    "        0 \t146.227879 \t0.0 \t0.0 \t146.227879\n",
    "        1 \t131.294226 \t0.0 \t0.0 \t131.294226\n",
    "        2 \t135.579913 \t0.0 \t0.0 \t135.579913\n",
    "        3 \t127.908073 \t0.0 \t0.0 \t127.908073\n",
    "        4 \t130.301921 \t0.0 \t0.0 \t130.301921\n",
    "        5 \t139.414369 \t0.0 \t0.0 \t139.414369\n",
    "        6 \t129.732767 \t0.0 \t0.0 \t129.732767\n",
    "        7 \t127.321448 \t0.0 \t0.0 \t127.321448\n",
    "        8 \t130.812973 \t0.0 \t0.0 \t130.812973\n",
    "        9 \t136.737979 \t0.0 \t0.0 \t136.737979\n",
    "        10 \t135.001893 \t0.0 \t0.0 \t135.001893\n",
    "        11 \t140.181680 \t0.0 \t0.0 \t140.181680\n",
    "        12 \t133.053322 \t0.0 \t0.0 \t133.053322\n",
    "        13 \t132.912917 \t0.0 \t0.0 \t132.912917\n",
    "        14 \t122.261415 \t0.0 \t0.0 \t122.261415\n",
    "        15 \t139.447081 \t0.0 \t0.0 \t139.447081\n",
    "        16 \t134.216364 \t0.0 \t0.0 \t134.216364\n",
    "        17 \t133.567210 \t0.0 \t0.0 \t133.567210\n",
    "        18 \t131.333447 \t0.0 \t0.0 \t131.333447\n",
    "        19 \t133.022141 \t0.0 \t0.0 \t133.022141\n",
    "        \n",
    "* **IDEA:** I should probably unit test the batch norm flow layer to make sure that it's doing what I think it should be doing... need to think about how to structure this experiment.\n",
    "* **CHECK**: Should `s` loss be negated also?  Seems like I need negative log loss, not just log loss..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-04-16\n",
    "\n",
    "* Forgot that BatchNorm has two components:  $\\mu, \\sigma^2$, the mean and variance of the batch, which we scale ($\\hat{x} = \\frac{x-\\mu}{\\sqrt{\\sigma^2 + \\epsilon}}$) AND two learnable parameters: $\\gamma, \\beta$, which are used to scale the output: $y = \\gamma \\hat{x} + \\beta$.  The learnable parameters are the only ones that change!\n",
    "* Now, how does that work when calculating the determinant? Let's see:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial y} \\hat{y} = \\frac{\\partial}{\\partial y}\\big[\\gamma * \\frac{x-\\mu}{\\sqrt{\\sigma^2 + \\epsilon} + \\beta}\\big]$$\n",
    "$$ = \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}}$$\n",
    "\n",
    "  Therefore, I need to include gamma in the determinant calculation in the batch norm layer!\n",
    "  \n",
    "  \n",
    "Ohhhhh... use `keras.layer.add_loss()` function instead of passing the new things over!  Not sure how to deal with batch though... https://www.tensorflow.org/guide/keras/custom_layers_and_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-04-17\n",
    "\n",
    "* Made some progress adding batch norm loss use both `layer.add_loss()` and `layer.add_metric()` so I can view it... BUT I need to upgrade to Tensorflow 2.0.  \n",
    "* After upgrading to 2.0, might as well start using `tf.keras` directly as that's the recommendation from the site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-04-20\n",
    "\n",
    "* Upgraded to Tensorflow 2.1!  I hate upgrading things...\n",
    "* Converted most of my code over too -- still need to add `layer.add_loss()` and `layer.add_metric()` to the `FlowBatchNorm()` layer though.  I did convert it over to the TF2 version, inheriting it and assuming that the fancier features are turned off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T12:56:16.075728Z",
     "start_time": "2020-04-20T12:56:10.894Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "for i in range(-10, 10):\n",
    "    eps = i / 1000\n",
    "    l = norm.cdf(0 - eps)\n",
    "    r = norm.cdf(0 + eps)\n",
    "    print(eps, '\\t', l - r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T12:56:16.076299Z",
     "start_time": "2020-04-20T12:56:10.898Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.array([[[-1, -2], [-3, -4]], [[1,2], [3, 4]], [[5,6], [7, 8]]])  \n",
    "b = np.array([100, 200]).reshape([1, 1, 2])\n",
    "\n",
    "c = a + b\n",
    "c[:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
