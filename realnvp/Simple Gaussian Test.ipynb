{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T15:44:34.969802Z",
     "start_time": "2020-04-05T15:44:33.509067Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import logit\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from keras.layers import (Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, Layer,\n",
    "                          Activation, Dropout, Conv2D, Conv2DTranspose,\n",
    "                          Concatenate, add, Add, Multiply)\n",
    "from keras.engine import InputSpec\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from realnvp_helpers import Mask, FlowBatchNorm\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T15:44:34.978676Z",
     "start_time": "2020-04-05T15:44:34.971821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4, 4, 3)\n",
      "(100, 4, 4, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 7.91728386, -3.74211666, -1.39937365],\n",
       "        [-4.54491778, -0.23326053, -0.77910284],\n",
       "        [ 0.25611969,  0.44484699,  2.62382611],\n",
       "        [ 4.17528109, -0.27181473,  2.78194168]],\n",
       "\n",
       "       [[-0.47577941,  0.99883384,  1.33806874],\n",
       "        [-2.13918905,  0.50927928, -5.57648648],\n",
       "        [ 2.16347973,  1.40567808, -2.43587834],\n",
       "        [-6.35771616, -1.08612996,  3.1987612 ]],\n",
       "\n",
       "       [[-2.35902617, -0.46983846, -2.36385492],\n",
       "        [-1.73405912,  0.54416087, -6.9883723 ],\n",
       "        [-4.30888353, -3.84526239, -0.74205784],\n",
       "        [-4.63604267,  1.15458543, -3.07438176]],\n",
       "\n",
       "       [[ 1.83255414, -1.19189994,  1.09591406],\n",
       "        [-2.32309297, -2.32885619,  5.81224811],\n",
       "        [-5.00856445,  5.85198909,  3.97918849],\n",
       "        [ 4.03387848,  3.81555843, -2.92012491]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "shape = (4, 4, 3)\n",
    "batch_shape = (batch_size,) + shape\n",
    "samples = 100\n",
    "print(batch_shape)\n",
    "\n",
    "train_data = np.random.normal(0.5, 3, size=(samples,) + (shape))\n",
    "print(train_data.shape)\n",
    "train_data[0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T15:44:35.092946Z",
     "start_time": "2020-04-05T15:44:34.980843Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_block(input_shape, kernel_size, filters, stage, block, use_resid=True):\n",
    "    ''' Adapted from resnet50 implementation in Keras '''\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    input_tensor = Input(batch_shape=input_shape)\n",
    "    x = Conv2D(filters1, (1, 1),\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    if use_resid:\n",
    "        x = add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return Model(input_tensor, x, name='conv_block' + stage + block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T15:47:46.445624Z",
     "start_time": "2020-04-05T15:47:46.433449Z"
    }
   },
   "outputs": [],
   "source": [
    "def coupling_step(input_shape, mask_type, stage):\n",
    "    ''' Implements (as per paper):\n",
    "        y = b * x + (1 - b) * [x * exp(s(b * x)) + t(b * x)]\n",
    "    '''\n",
    "    assert mask_type in ['check_even', 'check_odd', 'channel_even', 'channel_odd']\n",
    "    mask_prefix = 'check' if mask_type.startswith('check') else 'channel'\n",
    "    mask_opposite = 'odd' if mask_type.endswith('even') else 'even'\n",
    "    \n",
    "    input_tensor = Input(batch_shape=input_shape)\n",
    "    \n",
    "    # Raw operations for step\n",
    "    b0 = Mask(mask_type)\n",
    "    b1 = Mask(mask_prefix + '_' + mask_opposite)\n",
    "    s_ = conv_block(input_shape, (3, 3), (32, 32, 3), stage, '_s', use_resid=True)\n",
    "    t_ = conv_block(input_shape, (3, 3), (32, 32, 3), stage, '_t', use_resid=True)\n",
    "    batch = FlowBatchNorm()\n",
    "       \n",
    "    # Forward\n",
    "    masked_input = b1(input_tensor)\n",
    "    s = s_(masked_input)\n",
    "    t = t_(masked_input)\n",
    "    coupling = Lambda(lambda ins:  ins[0] * K.exp(ins[1]) + ins[2])([input_tensor, s, t])\n",
    "    coupling_mask = b0(coupling)\n",
    "    out1, out2 = Add()([masked_input, coupling_mask]), b0(s)\n",
    "    out1_norm, mean, var = batch(out1)\n",
    "    batch_loss = Lambda(lambda x: 0.5 * K.log(x + batch.epsilon), output_shape=(None, var.shape,))(var)\n",
    "    \n",
    "    # Reverse\n",
    "   \n",
    "    # Return result + masked scale for loss function\n",
    "    #return Model(input_tensor, [out1_norm, out2, batch_loss], name='_'.join(['coupling', mask_type, stage]))\n",
    "    return Model(input_tensor, [out1_norm, out2], name='_'.join(['coupling', mask_type, stage]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T15:47:59.186344Z",
     "start_time": "2020-04-05T15:47:59.178135Z"
    }
   },
   "outputs": [],
   "source": [
    "def coupling_layer(input_tensor, steps, mask_type, stage):\n",
    "    name_mapping = dict(enumerate(string.ascii_lowercase))\n",
    "    \n",
    "    # TODO: Only need check/channel, not even/odd right?\n",
    "    assert mask_type in ['check_even', 'check_odd', 'channel_even', 'channel_odd']\n",
    "    mask_prefix = 'check' if mask_type.startswith('check') else 'channel'\n",
    "    \n",
    "    input_shape = tuple(x.value for x in input_tensor.shape)\n",
    "    x = input_tensor\n",
    "    s_losses = []\n",
    "    batch_losses = []\n",
    "    for i in range(3):\n",
    "        mask_type = mask_prefix + ('_even' if i % 2 == 0 else '_odd')\n",
    "        step = coupling_step(input_shape, mask_type, stage=str(stage) + name_mapping[i])\n",
    "        #x, s, batch_loss = step(x)\n",
    "        x, s = step(x)\n",
    "        s_losses.append(s)\n",
    "        #batch_losses.append(batch_loss)\n",
    "    \n",
    "    #return x, s_losses, batch_losses\n",
    "    return x, s_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T15:48:00.514787Z",
     "start_time": "2020-04-05T15:48:00.508854Z"
    }
   },
   "outputs": [],
   "source": [
    "def realnvp_loss(target, output, shape):\n",
    "    # Extract x's and s's\n",
    "    z = output[0]\n",
    "    s_losses = output[1]\n",
    "    #batch_losses = output[2]\n",
    "    #z = output[:, :, :, :shape[-1]]\n",
    "    #s = output[:, :, :, shape[-1]:]\n",
    "   \n",
    "    # log(p_X(x)) = log(p_Z(f(x))) + log(|det(\\partial f(x) / \\partial X^T)|)\n",
    "    # Prior is standard normal(mu=0, sigma=1)\n",
    "    z_loss = -0.5 * np.log(math.pi) - 0.5 * z**2\n",
    "   \n",
    "    # Determinant is just sum of \"s\" params (already log-space)\n",
    "    det_loss = K.sum(s_losses)\n",
    "    \n",
    "    return -z_loss - det_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T15:49:13.616699Z",
     "start_time": "2020-04-05T15:49:06.177464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_51 (InputLayer)           (10, 4, 4, 3)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coupling_check_even_1a (Model)  [(10, 4, 4, 3), (10, 19498       input_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "coupling_check_odd_1b (Model)   [(10, 4, 4, 3), (10, 19498       coupling_check_even_1a[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "coupling_check_even_1c (Model)  [(10, 4, 4, 3), (10, 19498       coupling_check_odd_1b[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (10, 4, 4, 9)        0           coupling_check_even_1a[1][1]     \n",
      "                                                                 coupling_check_odd_1b[1][1]      \n",
      "                                                                 coupling_check_even_1c[1][1]     \n",
      "==================================================================================================\n",
      "Total params: 58,494\n",
      "Trainable params: 57,672\n",
      "Non-trainable params: 822\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(batch_shape=batch_shape)\n",
    "#x, s_losses, batch_losses = coupling_layer(input_tensor, steps=3, mask_type='check_even', stage=1)\n",
    "x, s_losses = coupling_layer(input_tensor, steps=3, mask_type='check_even', stage=1)\n",
    "s_losses = Concatenate()(s_losses)\n",
    "#batch_losses = concatenate()(batch_losses)\n",
    "\n",
    "forward_model = Model(inputs=input_tensor, outputs=[x, s_losses])\n",
    "optimizer = Adam(lr=0.001)\n",
    "forward_model.compile(optimizer=optimizer, \n",
    "                      loss=lambda target, output: realnvp_loss(target, output, shape=shape))\n",
    "forward_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T15:51:55.110453Z",
     "start_time": "2020-04-05T15:51:55.035878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbf0c1184a442e1b24c308bc751ace4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f696cb299cf84c9eb65b997ff2cf84b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [4] vs. [10]\n\t [[{{node training_4/Adam/gradients/loss_4/coupling_check_even_1c_loss/mul_1_grad/BroadcastGradientArgs}} = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@train...1_grad/Sum\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_4/Adam/gradients/loss_4/coupling_check_even_1c_loss/mul_1_grad/Shape, training_4/Adam/gradients/loss_4/coupling_check_even_1c_loss/mul_1_grad/Shape_1)]]\n\t [[{{node loss_4/coupling_check_even_1c_loss/Mean_2/_6777}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7089_loss_4/coupling_check_even_1c_loss/Mean_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-279b3a3f9039>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTQDMNotebookCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#, early_stopping, reduce_lr],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [4] vs. [10]\n\t [[{{node training_4/Adam/gradients/loss_4/coupling_check_even_1c_loss/mul_1_grad/BroadcastGradientArgs}} = BroadcastGradientArgs[T=DT_INT32, _class=[\"loc:@train...1_grad/Sum\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_4/Adam/gradients/loss_4/coupling_check_even_1c_loss/mul_1_grad/Shape, training_4/Adam/gradients/loss_4/coupling_check_even_1c_loss/mul_1_grad/Shape_1)]]\n\t [[{{node loss_4/coupling_check_even_1c_loss/Mean_2/_6777}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_7089_loss_4/coupling_check_even_1c_loss/Mean_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "#early_stopping = keras.callbacks.EarlyStopping('val_loss', min_delta=50.0, patience=5)\n",
    "#reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001)\n",
    "s = [int(x) for x in s_losses.shape]\n",
    "s[0] = int(train_data.shape[0])\n",
    "history = forward_model.fit(\n",
    "    train_data, [train_data, np.zeros(s)],\n",
    "    batch_size=batch_size,\n",
    "    epochs=20,\n",
    "    callbacks=[TQDMNotebookCallback()], #, early_stopping, reduce_lr],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T15:44:40.741984Z",
     "start_time": "2020-04-05T15:44:33.524Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "display(df.describe(percentiles=[0.25 * i for i in range(4)] + [0.95, 0.99]))\n",
    "col = 'val_loss' if 'val_loss' in df else 'loss'\n",
    "df[col][-25:].plot(figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-07-28\n",
    "\n",
    "* Got some framework up to do coupling layers but having trouble passing the scale parameter to the loss function, getting some weird tensorflow error, needs more debugging\n",
    "* Without the determinant in the loss function, it looks like loss goes down, so maybe on the right track?\n",
    "    * It's actually weird that we're not using the image in the output, but I guess that's what's great about this reversible model!\n",
    "* TODO:\n",
    "    * Debug scale function in loss\n",
    "    * Add reverse (generator) network to functions above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-07-29\n",
    "\n",
    "* Explanation of how to estimate probability of continuous variables (relevant for computing bits/pixel without an explicit discrete distribution): https://math.stackexchange.com/questions/2818318/probability-that-a-sample-is-generated-from-a-distribution\n",
    "* Idea for a post, explain likelihood estimation of discrete vs. continuous distributions (like pixels), include:\n",
    "  * Probability of observing a value from continuous distribution = 0\n",
    "     * https://math.stackexchange.com/questions/2818318/probability-that-a-sample-is-generated-from-a-distribution\n",
    "  * Probability of observing a value from a set of discrete hypthesis (models) is non-zero using epsilon trick (see above link):\n",
    "     * https://math.stackexchange.com/questions/920241/can-an-observed-event-in-fact-be-of-zero-probability\n",
    "  * Explain Equation 3 from \"A NOTE ON THE EVALUATION OF GENERATIVE MODELS\"\n",
    "     * Also include an example using a simpler case, like a bernoulli variable that we're estimating using a continuous distribution\n",
    "  * Bring it back to modelling pixels and how they usually do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-03-30\n",
    "\n",
    "* To make reversible network, build forward and backward network at the same time using `Model()` to have components that I can use in both networks\n",
    "* Looks like I have some instability here, depending on the run I can get an exact fit (-100s loss) or a poor a fit (+10):\n",
    "    * Turning off residual networks helps\n",
    "    * Adjusting the learning rate, batch size helps but hard to pinpoint a methodology\n",
    "* Most likely it's the instability of using a scale parameter (RealNVP paper Section 3.7), might need to implement their batch norm for more stable results, especially when adding more layers:\n",
    "    * Reimplement `BatchNorm`: https://github.com/keras-team/keras/blob/master/keras/layers/normalization.py\n",
    "    * Except return regular result AND (variance + eps) term\n",
    "    * Use the (var + eps) term to compute Jacobian for loss function (should just be log-additive)\n",
    "* Once this is done, add back the other stuff:\n",
    "    * Turn on residual shortcuts\n",
    "    * Change batch size to reasonable number and learning rate=0.01\n",
    "* If this still doesn't work, might want to implement \"Running average over recent minibatches\" in Appendix E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-03-31\n",
    "\n",
    "* Fixed a bug (I think) in the network where the coupling layer was wrong.  However, it still sometimes get stuck at around a loss of 5 but more often than not (on another training run) get to -10 (after 20 iters).\n",
    "* Trying to get FlowBatchNorm worknig but having some issues passing the determinant batch loss as an output because the `batch_size` is not getting passed (it has dimension (3,) but should have dimension (None, 3)).  Need to figure out how to tranlate a tensor to Layer that includes batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-04-05\n",
    "\n",
    "* Reminder: BatchNormalization on conv layers only need to normalize across [B, W, H, :] layers, not the \"C\" layer because the filter is identical across a channel (so it uses the same mean/var to normalize).  This is nice because it's the same axis (-1) you would normalize across in a Dense layer. See: https://intellipaat.com/community/3872/batch-normalization-in-convolutional-neural-network\n",
    "* I think I figured out how to return the batchnorm weights back but now I'm hitting a roadblock when I try to merge them together to put as part of the output loss -- maybe I should just forget it and use the tensors directly in the output loss?\n",
    "* Now that I switched to an explicit batch size, it doesn't run anymore... get this error \"Incompatible shapes: [4] vs. [32]\", probably some assumption that I had, got to work backwards and fix it I think.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T15:44:40.742710Z",
     "start_time": "2020-04-05T15:44:33.539Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "for i in range(-10, 10):\n",
    "    eps = i / 1000\n",
    "    l = norm.cdf(0 - eps)\n",
    "    r = norm.cdf(0 + eps)\n",
    "    print(eps, '\\t', l - r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
