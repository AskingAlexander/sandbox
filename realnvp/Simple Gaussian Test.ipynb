{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:22:48.870118Z",
     "start_time": "2020-04-14T11:22:47.445662Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import logit\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from keras.layers import (Input, Dense, Lambda, Flatten, Reshape, BatchNormalization, Layer,\n",
    "                          Activation, Dropout, Conv2D, Conv2DTranspose,\n",
    "                          Concatenate, add, Add, Multiply)\n",
    "from keras.engine import InputSpec\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from realnvp_helpers import Mask, FlowBatchNorm\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:22:48.879918Z",
     "start_time": "2020-04-14T11:22:48.872103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4, 4, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 2.39737367,  0.95210242,  0.64810124],\n",
       "        [-8.22022939, -2.15657331,  2.1342171 ],\n",
       "        [-3.19424176,  6.19328654,  3.47319153],\n",
       "        [ 1.70353651, -0.02966626, -4.70181249]],\n",
       "\n",
       "       [[ 1.7666883 , -0.27133969, -1.23252509],\n",
       "        [ 5.97340951, -4.12588782,  4.72224904],\n",
       "        [ 0.33829784,  2.35729313, -1.14711741],\n",
       "        [ 1.61496026, -0.04470453, -1.24002755]],\n",
       "\n",
       "       [[ 0.27637592, -3.07884897, -2.51646088],\n",
       "        [-0.34550501, -0.10814318, -4.11307939],\n",
       "        [ 1.81050528,  3.19157547,  2.69018771],\n",
       "        [ 0.64265902, -0.31655335, -1.72579811]],\n",
       "\n",
       "       [[ 3.58469524, -1.25383402,  2.03535011],\n",
       "        [-0.42593855, -0.97627318,  0.02600372],\n",
       "        [ 0.69820319,  1.98653491, -4.20218565],\n",
       "        [-0.80496272,  7.62116342, -0.41818718]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "shape = (4, 4, 3)\n",
    "samples = 100\n",
    "\n",
    "train_data = np.random.normal(0.5, 3, size=(samples,) + (shape))\n",
    "print(train_data.shape)\n",
    "train_data[0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:22:48.989615Z",
     "start_time": "2020-04-14T11:22:48.881413Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv_block(input_shape, kernel_size, filters, stage, block, use_resid=True):\n",
    "    ''' Adapted from resnet50 implementation in Keras '''\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    x = Conv2D(filters1, (1, 1),\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               kernel_initializer='he_normal',\n",
    "               name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    if use_resid:\n",
    "        x = add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return Model(input_tensor, x, name='conv_block' + stage + block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T12:03:15.604180Z",
     "start_time": "2020-04-14T12:03:15.597889Z"
    }
   },
   "outputs": [],
   "source": [
    "def coupling_step(input_shape, mask_type, stage):\n",
    "    ''' Implements (as per paper):\n",
    "        y = b * x + (1 - b) * [x * exp(s(b * x)) + t(b * x)]\n",
    "    '''\n",
    "    assert mask_type in ['check_even', 'check_odd', 'channel_even', 'channel_odd']\n",
    "    mask_prefix = 'check' if mask_type.startswith('check') else 'channel'\n",
    "    mask_opposite = 'odd' if mask_type.endswith('even') else 'even'\n",
    "    \n",
    "    input_tensor = Input(shape=input_shape)\n",
    "    \n",
    "    # Raw operations for step\n",
    "    b0 = Mask(mask_type)\n",
    "    b1 = Mask(mask_prefix + '_' + mask_opposite)\n",
    "    s_ = conv_block(input_shape, (3, 3), (32, 32, 3), stage, '_s', use_resid=True)\n",
    "    t_ = conv_block(input_shape, (3, 3), (32, 32, 3), stage, '_t', use_resid=True)\n",
    "    batch = FlowBatchNorm()\n",
    "       \n",
    "    # Forward\n",
    "    masked_input = b1(input_tensor)\n",
    "    s = s_(masked_input)\n",
    "    t = t_(masked_input)\n",
    "    coupling = Lambda(lambda ins:  ins[0] * K.exp(ins[1]) + ins[2])([input_tensor, s, t])\n",
    "    coupling_mask = b0(coupling)\n",
    "    out1, out2 = Add()([masked_input, coupling_mask]), b0(s)\n",
    "    out1_norm, mean, var = batch(out1)\n",
    "    batch_loss = Lambda(lambda x: 0.5 * K.log(x + batch.epsilon))(var)\n",
    "    \n",
    "    # Reverse\n",
    "   \n",
    "    # Return result + masked scale for loss function\n",
    "    return Model(input_tensor, [out1_norm, out2, batch_loss], name='_'.join(['coupling', mask_type, stage]))\n",
    "    #return Model(input_tensor, [out1_norm, out2], name='_'.join(['coupling', mask_type, stage]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T12:03:16.459548Z",
     "start_time": "2020-04-14T12:03:16.451452Z"
    }
   },
   "outputs": [],
   "source": [
    "def coupling_layer(input_tensor, steps, mask_type, stage):\n",
    "    name_mapping = dict(enumerate(string.ascii_lowercase))\n",
    "    \n",
    "    # TODO: Only need check/channel, not even/odd right?\n",
    "    assert mask_type in ['check_even', 'check_odd', 'channel_even', 'channel_odd']\n",
    "    mask_prefix = 'check' if mask_type.startswith('check') else 'channel'\n",
    "    \n",
    "    input_shape = tuple(x.value for x in input_tensor.shape)\n",
    "    x = input_tensor\n",
    "    s_losses = []\n",
    "    batch_losses = []\n",
    "    for i in range(3):\n",
    "        mask_type = mask_prefix + ('_even' if i % 2 == 0 else '_odd')\n",
    "        step = coupling_step(input_shape, mask_type, stage=str(stage) + name_mapping[i])\n",
    "        #x, s, batch_loss = step(x)\n",
    "        x, s = step(x)\n",
    "        s_losses.append(s)\n",
    "        #batch_losses.append(batch_loss)\n",
    "    \n",
    "    #return x, s_losses, batch_losses\n",
    "    return x, s_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T12:06:52.561149Z",
     "start_time": "2020-04-14T12:06:52.555190Z"
    }
   },
   "outputs": [],
   "source": [
    "def realnvp_zloss(target, z):\n",
    "    # log(p_X(x)) = log(p_Z(f(x))) + log(|det(\\partial f(x) / \\partial X^T)|)\n",
    "    # Prior is standard normal(mu=0, sigma=1)\n",
    "    shape = z.shape\n",
    "    return K.sum(-0.5 * np.log(math.pi) - 0.5 * z**2, axis=list(range(1, len(shape[1:]))))\n",
    "\n",
    "def realnvp_sumloss(target, output):\n",
    "    # Determinant is just sum of \"s\" or \"batch loss\" params (already log-space)\n",
    "    shape = output.shape\n",
    "    return K.sum(output, axis=list(range(1, len(shape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T12:06:56.998870Z",
     "start_time": "2020-04-14T12:06:53.131303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_173 (InputLayer)          (None, 4, 4, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "coupling_check_even_a0 (Model)  [(None, 4, 4, 3), (N 19498       input_173[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "s_losses (Concatenate)          (None, 4, 4, 6)      0           coupling_check_even_a0[1][1]     \n",
      "                                                                 coupling_check_even_a0[1][1]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_losses (Concatenate)      (None, 4, 4, 6)      0           coupling_check_even_a0[1][2]     \n",
      "                                                                 coupling_check_even_a0[1][2]     \n",
      "==================================================================================================\n",
      "Total params: 19,498\n",
      "Trainable params: 19,224\n",
      "Non-trainable params: 274\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=shape)\n",
    "#x = conv_block(shape, (3, 3), (32, 32, 3), '0', '_s', use_resid=True)(input_tensor)\n",
    "step = coupling_step(shape, 'check_even', stage=str('a') + '0')\n",
    "x, s, batch_loss = step(input_tensor)\n",
    "s_losses = [s, s]\n",
    "batch_losses = [batch_loss, batch_loss]\n",
    "\n",
    "#x, s_losses, batch_losses = coupling_layer(input_tensor, steps=3, mask_type='check_even', stage=1)\n",
    "#x, s_losses = coupling_layer(input_tensor, steps=3, mask_type='check_even', stage=1)\n",
    "s_losses = Concatenate(name='s_losses')(s_losses)\n",
    "batch_losses = Concatenate(name='batch_losses')(batch_losses)\n",
    "\n",
    "forward_model = Model(inputs=input_tensor, outputs=[x, s_losses, batch_losses])\n",
    "optimizer = Adam(lr=0.001)\n",
    "forward_model.compile(optimizer=optimizer, \n",
    "                      loss=[realnvp_zloss, realnvp_sumloss, realnvp_sumloss])\n",
    "forward_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T12:07:18.341232Z",
     "start_time": "2020-04-14T12:06:57.000690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d356fb85c7d74edcbfac89183c5673e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 15'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 16'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 17'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 18'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 19'), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#early_stopping = keras.callbacks.EarlyStopping('val_loss', min_delta=50.0, patience=5)\n",
    "#reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001)\n",
    "s = [len(train_data)] + [int(x) for x in s_losses.shape[1:]]\n",
    "#s[0] = int(train_data.shape[0])\n",
    "#print(train_data.shape, np.zeros(s).shape)\n",
    "\n",
    "#index = list(range(len(train_data)))\n",
    "#np.random.shuffle(index)\n",
    "#assert len(index) % batch_size == 0, (len(index), batch_size)\n",
    "#for i in range(len(index) // batch_size):\n",
    "#    data = train_data[i * batch_size:(i + 1) * batch_size, : , :, :]\n",
    "#    print(forward_model.train_on_batch(data, data))\n",
    "\n",
    "history = forward_model.fit(\n",
    "    train_data, [train_data, np.zeros(s), np.zeros(s)],\n",
    "    batch_size=batch_size,\n",
    "    epochs=20,\n",
    "    callbacks=[TQDMNotebookCallback()], #, early_stopping, reduce_lr],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T12:07:18.479565Z",
     "start_time": "2020-04-14T12:07:18.342908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>coupling_check_even_a0_loss</th>\n",
       "      <th>s_losses_loss</th>\n",
       "      <th>batch_losses_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>93.534915</td>\n",
       "      <td>-19.121853</td>\n",
       "      <td>0.563702</td>\n",
       "      <td>112.093065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.415755</td>\n",
       "      <td>1.307278</td>\n",
       "      <td>2.331175</td>\n",
       "      <td>6.048807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>89.341567</td>\n",
       "      <td>-21.413466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106.872086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0%</th>\n",
       "      <td>89.341567</td>\n",
       "      <td>-21.413466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106.872086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.864900</td>\n",
       "      <td>-20.130177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>109.040127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>92.024971</td>\n",
       "      <td>-19.007449</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>111.254961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.692141</td>\n",
       "      <td>-18.042383</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>113.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>94.895223</td>\n",
       "      <td>-17.373452</td>\n",
       "      <td>1.290907</td>\n",
       "      <td>115.576273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>122.162163</td>\n",
       "      <td>-17.252121</td>\n",
       "      <td>8.608617</td>\n",
       "      <td>131.725367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>128.978898</td>\n",
       "      <td>-17.221788</td>\n",
       "      <td>10.438044</td>\n",
       "      <td>135.762640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss  coupling_check_even_a0_loss  s_losses_loss  \\\n",
       "count   20.000000                    20.000000      20.000000   \n",
       "mean    93.534915                   -19.121853       0.563702   \n",
       "std      8.415755                     1.307278       2.331175   \n",
       "min     89.341567                   -21.413466       0.000000   \n",
       "0%      89.341567                   -21.413466       0.000000   \n",
       "25%     90.864900                   -20.130177       0.000000   \n",
       "50%     92.024971                   -19.007449       0.000010   \n",
       "75%     92.692141                   -18.042383       0.001096   \n",
       "95%     94.895223                   -17.373452       1.290907   \n",
       "99%    122.162163                   -17.252121       8.608617   \n",
       "max    128.978898                   -17.221788      10.438044   \n",
       "\n",
       "       batch_losses_loss  \n",
       "count          20.000000  \n",
       "mean          112.093065  \n",
       "std             6.048807  \n",
       "min           106.872086  \n",
       "0%            106.872086  \n",
       "25%           109.040127  \n",
       "50%           111.254961  \n",
       "75%           113.086957  \n",
       "95%           115.576273  \n",
       "99%           131.725367  \n",
       "max           135.762640  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3f8df25e48>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "display(df.describe(percentiles=[0.25 * i for i in range(4)] + [0.95, 0.99]))\n",
    "col = 'val_loss' if 'val_loss' in df else 'loss'\n",
    "df[col][-25:].plot(figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-07-28\n",
    "\n",
    "* Got some framework up to do coupling layers but having trouble passing the scale parameter to the loss function, getting some weird tensorflow error, needs more debugging\n",
    "* Without the determinant in the loss function, it looks like loss goes down, so maybe on the right track?\n",
    "    * It's actually weird that we're not using the image in the output, but I guess that's what's great about this reversible model!\n",
    "* TODO:\n",
    "    * Debug scale function in loss\n",
    "    * Add reverse (generator) network to functions above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-07-29\n",
    "\n",
    "* Explanation of how to estimate probability of continuous variables (relevant for computing bits/pixel without an explicit discrete distribution): https://math.stackexchange.com/questions/2818318/probability-that-a-sample-is-generated-from-a-distribution\n",
    "* Idea for a post, explain likelihood estimation of discrete vs. continuous distributions (like pixels), include:\n",
    "  * Probability of observing a value from continuous distribution = 0\n",
    "     * https://math.stackexchange.com/questions/2818318/probability-that-a-sample-is-generated-from-a-distribution\n",
    "  * Probability of observing a value from a set of discrete hypthesis (models) is non-zero using epsilon trick (see above link):\n",
    "     * https://math.stackexchange.com/questions/920241/can-an-observed-event-in-fact-be-of-zero-probability\n",
    "  * Explain Equation 3 from \"A NOTE ON THE EVALUATION OF GENERATIVE MODELS\"\n",
    "     * Also include an example using a simpler case, like a bernoulli variable that we're estimating using a continuous distribution\n",
    "  * Bring it back to modelling pixels and how they usually do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-03-30\n",
    "\n",
    "* To make reversible network, build forward and backward network at the same time using `Model()` to have components that I can use in both networks\n",
    "* Looks like I have some instability here, depending on the run I can get an exact fit (-100s loss) or a poor a fit (+10):\n",
    "    * Turning off residual networks helps\n",
    "    * Adjusting the learning rate, batch size helps but hard to pinpoint a methodology\n",
    "* Most likely it's the instability of using a scale parameter (RealNVP paper Section 3.7), might need to implement their batch norm for more stable results, especially when adding more layers:\n",
    "    * Reimplement `BatchNorm`: https://github.com/keras-team/keras/blob/master/keras/layers/normalization.py\n",
    "    * Except return regular result AND (variance + eps) term\n",
    "    * Use the (var + eps) term to compute Jacobian for loss function (should just be log-additive)\n",
    "* Once this is done, add back the other stuff:\n",
    "    * Turn on residual shortcuts\n",
    "    * Change batch size to reasonable number and learning rate=0.01\n",
    "* If this still doesn't work, might want to implement \"Running average over recent minibatches\" in Appendix E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-03-31\n",
    "\n",
    "* Fixed a bug (I think) in the network where the coupling layer was wrong.  However, it still sometimes get stuck at around a loss of 5 but more often than not (on another training run) get to -10 (after 20 iters).\n",
    "* Trying to get FlowBatchNorm worknig but having some issues passing the determinant batch loss as an output because the `batch_size` is not getting passed (it has dimension (3,) but should have dimension (None, 3)).  Need to figure out how to tranlate a tensor to Layer that includes batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-04-05\n",
    "\n",
    "* Reminder: BatchNormalization on conv layers only need to normalize across [B, W, H, :] layers, not the \"C\" layer because the filter is identical across a channel (so it uses the same mean/var to normalize).  This is nice because it's the same axis (-1) you would normalize across in a Dense layer. See: https://intellipaat.com/community/3872/batch-normalization-in-convolutional-neural-network\n",
    "* I think I figured out how to return the batchnorm weights back but now I'm hitting a roadblock when I try to merge them together to put as part of the output loss -- maybe I should just forget it and use the tensors directly in the output loss?\n",
    "* Now that I switched to an explicit batch size, it doesn't run anymore... get this error \"Incompatible shapes: [4] vs. [32]\", probably some assumption that I had, got to work backwards and fix it I think.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020-04-14\n",
    "\n",
    "* Okay figured out the weird error I was getting: when a Keras model has multiple outputs you either have to give it a list or dict of loss functions, otherwise it will apply the same loss to each output!  Of course, I just assumed that it gives you all outputs in one loss function. So silly!\n",
    "* I reverted the change to explicitly set batch. Instead in the `BatchNormFlow` layer I just multiply zero by the `inputs` and then add the mean/variance.  I think this gives the right shape?\n",
    "* TODOs:\n",
    "  * Check that shape/computation for `BatchNormFlow`/`batch_losses` loss is correct\n",
    "  * Check that loss functions are actually returning a negative log-loss (not just the log)\n",
    "  * Validate the model is fitting what I want (right now I have an elbow effect as I train more) -- should there be backprop through the batch_losses? I guess not?  Check the paper and figure out what to do.\n",
    "  * Add back in the bigger model that has multiple coupling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:22:51.015732Z",
     "start_time": "2020-04-14T11:22:47.456Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "for i in range(-10, 10):\n",
    "    eps = i / 1000\n",
    "    l = norm.cdf(0 - eps)\n",
    "    r = norm.cdf(0 + eps)\n",
    "    print(eps, '\\t', l - r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
